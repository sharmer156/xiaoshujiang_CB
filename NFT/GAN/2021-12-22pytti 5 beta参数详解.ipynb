---
title: 2021-12-22pytti 5 beta.ipynb 参数详解
tags: 
grammar_cjkRuby: true
---

https://colab.research.google.com/drive/10YWuTxtBI7PS0xBJCLAUjhR5cB0UUXe-#scrollTo=OoIL7ayzq7kC
2分图


https://colab.research.google.com/drive/12EDQtYQ9ZK1zotQeLlp2ye8PY1Wron_h#scrollTo=hqJ6vY2z3rR8
# 2.1 Parameters:

* * *
https://discord.com/channels/869630568818696202/870017848079155231
### Prompts关键词设定最多48个词，没有限制，|每个提示仅限于 77 个标记（大约约 330 个字符或约 38 个单词）

scenes:""scene_prefix:""scene_suffix:scene_suffix:""interpolation_steps:steps_per_scene:
## scenes 场景描述 scene_prefix 场景前缀 #scene_suffix:场景后缀 #
## 场景设置 粒子
scenes:
deep space habitation ring made of glass | galactic nebula | wow! space is full of fractal creatures darting around everywhere like fireflies
scene_prefix:
astrophotography #pixelart | image credit nasa | space full of cybernetic neon:3_galactic nebula | isometric pixelart by Sachin Teng | 
scene_suffix:
| satellite image:-1:-.95 | text:-1:-.95 | anime:-1:-.95 | watermark:-1:-.95 | backyard telescope:-1:-.95 | map:-1:-.95
interpolation_steps:
0
steps_per_scene:
601

rotate_3d
[cos(radians(1.5)), 0, -sin(radians(1.5))/sqrt(2), sin(radians(1.5))/sqrt(2)]
![enter description here](./images/1640154138751.png)
![enter description here](./images/1640154157707.png)



### Image Prompts:

direct_image_prompts:""

* * *

### Initial image:

init_image:""direct_init_weight:""semantic_init_weight:""

* * *

### Image:

Use `image_model` to select how the model will encode the image

image_model:       VQGANLimited PaletteUnlimited Palette     

| image_model | description | strengths | weaknesses |
| --- | --- | --- | --- |
| VQGAN | classic VQGAN image | smooth images | limited datasets, slow, VRAM intesnsive |
| Limited Palette | pytti differentiable palette | fast, VRAM scales with `palettes` | pixel images |
| Unlimited Palette | simple RGB optimization | fast, VRAM efficient | pixel images |

The output image resolution will be `width` × `pixel_size` by height × `pixel_size` pixels. The easiest way to run out of VRAM is to select `image_model` VQGAN without reducing `pixel_size` to 1.

For `animation_mode: 3D` the minimum resoultion is about 450 by 400 pixels.

width:height:pixel_size:smoothing_weight:

`VQGAN` specific settings:

vqgan_model:       imagenetcocowikiartsflckropenimages     

`Limited Palette` specific settings:

random_initial_palette:palette_size:palettes:gamma:hdr_weight:palette_normalization_weight:show_palette:target_palette:""lock_palette:

* * *

### Animation:

animation_mode:       off2D3DVideo Source     sampling_mode:       bilinearnearestbicubic     infill_mode:       mirrorwrapblacksmear     pre_animation_steps:steps_per_frame:frames_per_second:

* * *

### Stabilization Weights:

direct_stabilization_weight:""semantic_stabilization_weight:""depth_stabilization_weight:""edge_stabilization_weight:""

`flow_stabilization_weight` is used for `animation_mode: 3D` and `Video Source`

flow_stabilization_weight:""

* * *

### Video Tracking:

Only for `animation_mode: Video Source`.

video_path:""frame_stride:reencode_each_frame:flow_long_term_samples:

* * *

### Image Motion:

translate_x:""translate_y:""

`..._3d` is only used in 3D mode.

translate_z_3d:""

`rotate_3d` _must_ be a `[w,x,y,z]` rotation (unit) quaternion. Use `rotate_3d: [1,0,0,0]` for no rotation. [Learn more about rotation quaternions here](https://eater.net/quaternions).

rotate_3d:""

`..._2d` is only used in 2D mode.

rotate_2d:""zoom_x_2d:""zoom_y_2d:""

3D camera (only used in 3D mode):

lock_camera:field_of_view:near_plane:far_plane:

* * *

### Output:

file_namespace:""allow_overwrite:display_every:clear_every:display_scale:save_every:backups:show_graphs:approximate_vram_usage:

* * *

### Model:

Quality settings from Dribnet's CLIPIT (<https://github.com/dribnet/clipit>). Selecting too many will use up all your VRAM and slow down the model. I usually use ViTB32, ViTB16, and RN50 if I get a A100, otherwise I just use ViT32B.

| quality | CLIP models |
| --- | --- |
| draft | ViTB32 |
| normal | ViTB32, ViTB16 |
| high | ViTB32, ViTB16, RN50 |
| best | ViTB32, ViTB16, RN50x4 |

ViTB32:ViTB16:RN50:RN50x4:

the default learning rate is `0.1` for all the VQGAN models except openimages, which is `0.15`. For the palette modes the default is `0.02`.

learning_rate:reset_lr_each_frame:seed:

**Cutouts**:

[Cutouts are how CLIP sees the image.](https://twitter.com/remi_durant/status/1460607677801897990)

cutouts:cut_pow:cutout_border:

NOTE: prompt masks (`promt:weight_[mask.png]`) will not work right on '`wrap`' or '`mirror`' mode.

border_mode:       clampmirrorwrapblacksmear     顯示程式碼