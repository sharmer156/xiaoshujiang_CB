---
title: 2023-12-4构建企业级大语言模型应用的秘诀：GitHub Copilot 的实践之路
tags: 
grammar_cjkRuby: true
---


推荐阅读：《构建企业级大语言模型应用的秘诀：GitHub Copilot 的实践之路》

GitHub Copilot 是目前最成功的大语言模型应用之一，可以帮程序员自动生成可用的代码，已经有超过一百万付费用户。

GitHub Copilot 开发团队分享了构建这个产品时的经验教训。整个产品的开发历时三年，尽力了三个阶段：发现、实现和扩展。这三个阶段对于其他产品的研发也非常具有借鉴价值。

一、发现阶段：确定大语言模型应用可以解决的最核心的问题

这个阶段最难的其实是聚焦，就是确定并缩小问题的范围。我们很多人做产品，犯得最大的错误不是没想法，而是想法太多，什么都想做，最后都做不好。而 Copilot 一开始就是专注于软件开发生命周期中的一个特定环节——在集成开发环境（IDE）中编写函数。

二、实现阶段：通过迭代创造流畅的 AI 产品体验

产品开发另一个常犯的错误就是一次憋个大的，很长时间才能发布一个可用版本。GitHub Copilot 在产品开发过程中则是通过快速迭代，让团队迅速从失败中学习和成长。并且他们使用 A/B 测试快速验证新功能。

团队的成员都会”吃自己的狗粮“，也就是每天都使用自己做的产品，这样自己在用的过程中就能发现很多问题。比如他们最开始是做的网页界面，后来发现网页界面上操作需要频繁的在编辑器和界面之间切换，特别不方便，所以他们改成了将 GitHub Copilot 集成至到编辑器中后台运行，这样体验好了很多。

产品开发还有一个常见的错误就是过于在意沉没成本，也就是在某个项目或者方向上已经投入巨大，却因为不愿意放弃而继续坚持，哪怕明显转变方向更有利的情况。团队在最开始的时候，就投入了巨大精力为每个编程语言训练 AI 模型，后来发现大语言模型变强了后，一个模型就可以处理多种语言和任务，于是马上调整方向切换到大语言模型，而不纠结与在单一编程语言上训练消耗的沉没成本。

三、扩展阶段：优化 AI 的质量、可用性和负责任使用，助力产品达到正式发布 (GA)

当功能开发出来后，还需要考虑到投入生产环境大量用户使用的情况。GitHub Copilot 团队采取了一些有效手段来保障产品的发布和扩展。

他们通过 waiting list 的方式逐步放开测试，并且在测试过程中收集反馈并及时调整。

由于大语言模型是基于概率预测的，这意味着它们并不总能产生一致、可预测的结果。所以它们做了缓存，以及调整了参数降低随机性。另外还有很重要的一点是他们建立了数据监测机制，通过明确了产品的关键绩效指标，如代码的接受率和代码保留率（这是衡量开发者对原始代码建议的保留或编辑程度的指标），这样在发布测试或者新版本时，就能通过数据监测来及时了解版本的质量是否符合预期，出现问题可以及时回滚或者调整。

除此之外，他们也做了很多优化在不降低质量的前提下降低成本，比如前面提到的缓存，还有一个有一的案例，就是最开始他们在 AI 建议代码的时候，会生成 10 条建议结果（如果你用过早期版本应该记得），但是发现这样成本很高但大部分用户只会选择第一个，所以他们优化为只显示 1 个结果。

最后把他们的关键经验总结一下：

- 缩小范围，聚焦在特定的问题，并深入分析 AI 的潜在应用场景。这样做可以帮助应用程序产生更大的影响，并更快地推向市场。

- 在设计时就考虑到如何快速测试功能和收集数据反馈，因为对于大模型来说输出结果具有不确定性，而且绝大部分用户还在学习如何与 AI 互动。

- 在扩大规模时，持续收集用户反馈，考虑用户需求，确保能够提供真正有价值的功能。

原文：How to build an enterprise LLM application: Lessons from GitHub Copilot
https://github.blog/2023-09-06-how-to-build-an-enterprise-llm-application-lessons-from-github-copilot/

中文翻译：构建企业级大语言模型应用的秘诀：GitHub Copilot 的实践之路 [译] https://baoyu.io/translations/llm/how-to-build-an-enterprise-llm-application-lessons-from-github-copilot