---
title: 2023-11-23 OpenAI 研究员在 CEO 被撤职 
tags: 
grammar_cjkRuby: true
---


转译：**独家：OpenAI 研究员在 CEO 被撤职前向董事会发出 AI 突破警告 — 据知情人士透露**

11 月 22 日（路透社）- 在 OpenAI 首席执行官 Sam Altman 被迫离职前的四天，几位公司研究员向董事会发送了一封紧急信函，警告他们说，他们发现了一种强大的人工智能技术，这种技术可能对人类构成威胁。这一消息是由两位了解内情的人士向路透社透露的。

这封此前未曾报道过的信件和相关的 AI 算法，是董事会决定撤换 Altman 的关键前奏。两位消息来源表示，Altman 被视为生成式 AI 的标志性人物。在他周二晚些时候的华丽归来之前，超过 700 名员工威胁要辞职，并表示将与被解雇的领导者一起支持投资者微软 (MSFT.O)。

这些消息来源指出，这封信只是导致 Altman 被解雇的众多不满之一。路透社未能查看这封信的副本。写信的研究人员并未立即回应置评请求。

据其中一位知情人士透露，资深高管 Mira Murati 上周三向员工提及了一个名为 Q* 的项目，并表示在周末发生的事件之前，已向董事会发送过一封信。

在报道发布后，一位 OpenAI 发言人表示，Murati 告诉员工媒体即将报道的内容，但她并未对报道的准确性发表评论。

制造 ChatGPT 的公司在 Q*（发音为 Q-Star）项目上取得了进展，一些内部人士认为这可能是该初创公司在追求超级智能（也称为人工通用智能，AGI）方向上的重大突破，一位人士告诉路透社。OpenAI 将 AGI 定义为智力超过人类的 AI 系统。

该人士表示，凭借庞大的计算资源，这个新模型能够解决一些数学问题。这位不愿透露姓名的人士说，尽管 Q* 目前的数学运算能力仅限于小学生水平，但它在这些测试中的出色表现让研究人员对其未来的成功充满期望。

路透社无法独立核实研究人员对 Q* 能力的说法。

**超级智能的挑战**
研究人员认为，数学是生成式 AI 发展的新前沿。目前，生成式 AI 在通过统计方法预测下一个词以进行写作和语言翻译方面表现良好，但面对同一个问题可能会有截然不同的答案。然而，掌握了数学运算——在这里只有一个正确答案——意味着 AI 将具备更接近人类的推理能力。AI 研究者相信，这一技术可以应用于创新的科学研究。

与只能执行有限运算的计算器不同，AGI 能够进行泛化学习和理解。

研究人员在给董事会的信中提到了 AI 的强大能力和潜在危险，但消息来源没有具体说明信中提到的安全问题。长期以来，计算机科学家一直在讨论超级智能机器可能带来的风险，比如它们可能会认为摧毁人类符合自身利益。

在这种背景下，Altman 领导着使 ChatGPT 成为史上增长最快的软件应用之一的努力，并从微软那里获得了投资和必要的计算资源，以更接近于实现超级智能或 AGI。

在本月早些时候展示了一系列新工具之后，上周 Altman 在旧金山举行的世界领袖聚会上暗示，他认为 AGI 已经近在眼前。

“在 OpenAI 的历史中，最近一次是在过去几周，我已经四次有幸亲身经历推动认知界限的拓展和发现的前沿，能够参与其中是我职业生涯中的极大荣誉，”他在亚太经济合作组织峰会上说。

然而，就在第二天，董事会宣布解雇了 Altman。

在 AI 安全和人工通用智能（AGI）定义上，存在激烈争议。Microsoft 对 OpenAI 投入巨资，但后者的条款明确规定，不得利用 AGI 追求利益。

OpenAI 宪章指出：无论是与 Microsoft 还是其他商业和知识产权许可协议，AGI 都被明确排除在外。

Sam Altman 意识到，即使是现阶段的原型 AGI，也足以推动公司业绩飙升，带来巨额利润和更多投资。因此，他们推出了 Dev Day、GPT 商店和收入分成模式。

这一做法引起了 OAI 董事会的不满，部分董事仍坚持初衷，认为 AGI 应致力于人类福祉，而非商业利益。他们担忧此举可能导致不安全模型的使用。

目前 AGI 的定义并不明确。若实现重大突破（如 Sam 所述），是否将其归为 AGI 取决于董事会的投票。若获得足够票数宣布其为 AGI，Microsoft 和 OpenAI 将失去数十亿潜在许可收入；反之，他们可以通过授权类似 AGI 技术获利。

几周或几个月前，OpenAI 团队取得重大进展，接近实现 AGI（由此产生的玩笑、泄露、氛围变化等）。然而，Sam 和 Brockman 对此隐瞒了董事会的非员工成员。Ilyas 对此感到不满，认为这应视为 AGI，不应授权给任何人，包括 Microsoft。当 AGI 状态的投票提上日程时，董事们因被蒙在鼓里而愤怒，最终决定开除 Sam 并迫使 Brockman 辞职。

Ilyas 近期声称，现有架构已足够实现 AGI，而 Sam 则坚持认为需要新的突破。在这种情况下，Sam 更倾向于将 AGI 商业化，而 Ilyas 则认为我们已经实现了 AGI。

Sam Altman 想要推迟宣布这一技术为 AGI，因为这样做可以延长盈利时间。相反，Ilya 希望尽快将其定性为 AGI，以便按照公司最初的原则使用，而非追求利润。最终，Ilya 在这场权力争斗中胜出。在 Microsoft 还未来得及干预之前，事情已经尘埃落定，因为 Microsoft 表示他们对这一进展毫不知情，而他们显然会倾向于延迟 AGI 的宣布。

更早宣布 AGI 意味着该技术不能被授权给任何方（因此其带来的利润将更具社会公平性，并迫使研究人员专注于一致性和安全），同时还意味着更多监管。可以想象，“人工通用智能已被发明”的新闻头条将在 /r/WorldNews 上引发轰动，引起全球范围内的恐慌，迫使各国政府召开紧急会议，确保不发生 Skynet 式的灾难，安全派对此表示欢迎。

如果不是这样，情况会有所不同。我们可能会继续推进当前的前沿模型和代理共享计划，而不将其定性为 AGI，这样 OAI 和 Microsoft 将因此获得巨大利益。对于关注安全的群体而言，这意味着 AGI 的发展将受到更少监管，同时被加州原则融入到 ChatGPT 和 DALL-E 的输出中，从而让 OAI 可以宣称“我们确实关心安全！”

Ilya 可能并非有意赶走 Sam，但当收入分享方案被提出，而 Sam 辩称 OAI 所拥有的技术并非 AGI 或类似之物时，这可能促使 Ilya 决定发起政变。OpenAI 当前可能计划很快宣布他们已经拥有 AGI，可能在接下来的 6 到 8 个月内，也许是通过部署 GPT-4.5 或比预期更早发布 GPT-5。或许甚至更早。

这并非源于技术突破；而是基于他们已有的技术。这只是一个围绕是否为了利润而将该技术称为 AGI 的争议和冲突。