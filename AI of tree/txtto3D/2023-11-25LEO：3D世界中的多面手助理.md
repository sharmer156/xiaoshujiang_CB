---
title: 2023-11-25LEO：3D世界中的多面手助理
tags: 
grammar_cjkRuby: true
---


LEO：3D世界中的多面手代理

LEO是一个多模态、多任务的智能体，它能够在3D环境中进行感知、定位、推理、规划和行动。

LEO通过结合大语言模型的知识和学习方案，展示了在多个领域（包括自然语言处理、计算机视觉和机器人技术）中解决通用任务的能力。

LEO的独特之处在于它能够在3D环境中理解和执行基于语言的指令，这使其在多种复杂任务中具有广泛的应用潜力。

主要功能和作用：

1、3D视觉-语言理解：LEO能够理解3D环境中的视觉信息，并将其与语言描述相结合。这意味着它可以看到一个物体（如苹果），并理解相关的语言描述（如“这是一个苹果”）。

2、执行语言指令：它能够根据语言指令执行动作。例如，如果有人指示“把苹果放在桌子上”，LEO能够理解这一指令并执行相应的动作。

3、多样化的3D任务执行：LEO在多种3D任务上表现出色，包括3D字幕（为场景中的物体或事件创建描述性文字）、问答（回答关于3D环境的问题）、具身推理（在3D环境中进行逻辑推理）、具身导航（在3D空间中找到特定的位置或物体）和机器人操控（控制机器人执行特定任务）。

为了训练LEO，研究者们创建了一个大型的数据集，包含了各种3D环境中的任务，这些任务需要深入理解和与3D世界的互动。

LEO在多种3D任务上进行了测试，包括：

•3D字幕：为3D场景中的物体或事件创建描述性文字。
•问答：回答关于3D环境的问题。
•具身推理：在3D环境中进行逻辑推理。
•具身导航：在3D空间中找到特定的位置或物体。
•机器人操控：控制机器人执行特定任务。

LEO在这些任务上表现出色，显示了它在多样化任务中的熟练程度。

工作原理：

1、两阶段训练：

LEO的训练分为两个阶段：

•3D视觉-语言对齐：在这一阶段，LEO学习如何将3D图像与语言描述相结合。这涉及到理解视觉信息和语言信息之间的关系。
•3D视觉-语言-动作指令调整：在这一阶段，LEO学习如何根据语言指令执行具体的动作。这需要它理解指令并将其转化为动作。

2、大规模数据集：为了支持这种训练，研究者们创建了一个包含多种3D环境任务的大规模数据集。这些任务需要深入理解和与3D世界的互动。

3、多模态学习：LEO结合了视觉信息（如图像和视频）和语言信息（如文字描述），使其能够在多模态环境中工作。

4、广泛的应用能力：通过这种训练和数据集，LEO能够在多种3D任务中表现出色，展示了其广泛的应用能力。

项目及演示：https://embodied-generalist.github.io
论文：https://arxiv.org/abs/2311.12871
GitHub：https://github.com/embodied-generalist/embodied-generalist