---
title: 2024-2-23微软推出LongRoPE，可以将LLM上下文窗口扩展到200万个令牌以上
tags: 
grammar_cjkRuby: true
---

炸裂了，微软来砸场子了 哈哈哈哈

微软推出LongRoPE，可以将LLM上下文窗口扩展到200万个令牌以上🤣

Gemini 1.5刚搞了100万令牌的，这就来砸场子

LongRoPE能够在仅需最多1000步的微调内，即可完成从短上下文到长上下文的扩展。

同时还能保持原有短上下文窗口的性能。

LongRoPE的功能特点

1、扩展上下文窗口至200万令牌：LongRoPE首次实现了将预训练大型语言模型（LLM）的上下文窗口扩展到2048k（200万）令牌，这一点对于需要处理极长文本的任务来说是一个重大突破。

2、低成本微调：与传统需要大量微调步骤的方法不同，LongRoPE能够在仅需最多1000步的微调内，即可完成从短上下文到长上下文的扩展，大大降低了训练成本和时间。

3、保持短上下文性能：在扩展上下文窗口的同时，LongRoPE还能保持原有短上下文窗口的性能，这意味着模型在处理不同长度文本时能够保持高效和准确。

4、三大关键创新：

△ 非均匀位置插值：通过识别和利用位置插值中的两种非均匀性，LongRoPE为微调提供了更好的初始化，允许在无需微调的场景下实现8倍的扩展。

发现非均匀性：LongRoPE首先识别出在位置插值中存在的两种非均匀性：不同的RoPE（Rotary Positional Encoding）维度和令牌位置。这意味着不同位置的令牌和不同的维度应该有不同的处理方式，以保持信息的有效传递。

有效搜索和应用：通过有效的搜索方法，LongRoPE找到了一种方法，可以在不同的RoPE维度和令牌位置上应用不同的插值策略。这种策略能够更好地初始化模型进行微调，允许在不需要微调的情况下实现上下文窗口的显著扩展。

△ 渐进式扩展策略：采用先微调一个256k长度LLM，然后进行第二次位置插值以达到2048k上下文窗口的策略，避免了直接在极长文本上微调的需要。

分阶段微调：LongRoPE采用了一种渐进式扩展策略，先是在一个较短的256k长度上微调LLM，然后再对这个已经微调过的模型进行第二次位置插值，以此达到2048k（200万）令牌的上下文窗口。这种方法避免了直接在极长文本上进行微调的需求，从而减少了计算资源的消耗。

效率和性能：通过这种分阶段的方法，LongRoPE能够在保持模型性能的同时，有效地扩展模型的上下文窗口，避免了直接在极长文本上微调时可能遇到的问题。

△ 调整性能以恢复短上下文窗口性能：通过在扩展LLM上调整RoPE重缩放因子，缓解了原始（较短）上下文窗口性能下降的问题。

动态调整RoPE：为了确保在扩展上下文窗口后，模型在处理短文本时依然保持高性能，LongRoPE对扩展后的LLM的RoPE重缩放因子进行了调整。这一步骤是为了确保模型在不同长度的文本上都能保持良好的性能。

保证模型灵活性：通过这种动态调整机制，LongRoPE确保了模型不仅能处理极长的文本，同时在处理短文本时也不会出现性能下降，使得模型在不同场景下都能发挥出良好的表现。

5、广泛的应用潜力：LongRoPE的技术可以应用于任何基于RoPE嵌入的LLMs，对于各种长上下文任务显示出了卓越的效果，如提高语言模型在长文本上的理解和生成能力，提升机器阅读理解、文本摘要和长篇文章生成等任务的性能。

论文：https://arxiv.org/abs/2402.13753
PDF：https://arxiv.org/pdf/2402.13753.pdf
![enter description here](https://i.imgur.com/ZETAXHm.jpeg)