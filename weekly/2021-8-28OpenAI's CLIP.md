---
title: 2021-8-28OpenAI's CLIP
tags: 
grammar_cjkRuby: true
---

# List of sites/programs/projects that use OpenAI's CLIP neural network for steering image/video creation to match a text description

![](https://www.redditstatic.com/desktop2x/img/renderTimingPixel.png)[Project](https://www.reddit.com/r/MachineLearning/search?q=flair_name%3A%22Project%22&restrict_sr=1)

Many of the items on this list are Google Colaboratory ("Colab" for short) notebooks. [Here](https://colab.research.google.com/notebooks/intro.ipynb) is an introduction to Google Colab, and there is also a [Google Colab FAQ](https://research.google.com/colaboratory/faq.html).

Some of the Colab notebooks create output files in the remote computer's file system. These files can be accessed by clicking the Files icon in the left part of the Colab window.

For the [BigGAN](https://aiweirdness.com/post/178619746932/imaginary-worlds-dreamed-by-biggan) image generators on this list that allow the initial class (i.e. type of object) to be specified, [here](https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a) is a list of the 1,000 BigGAN classes.

For the [StyleGAN](https://medium.com/syncedreview/nvidia-open-sources-hyper-realistic-face-generator-stylegan-f346e1a73826) image generators on this list that allow the specification of the StyleGAN2 .pkl file, [here](https://github.com/justinpinkney/awesome-pretrained-stylegan2) is a list of them.

List of sites/programs/projects that use OpenAI's [CLIP](https://openai.com/blog/clip/) neural network for steering image/video creation to match a text description:

1.  (Added Aug. 11, 2021) [List part created on August 11, 2021](https://www.reddit.com/user/Wiskkey/comments/p2j673/list_part_created_on_august_11_2021/).

2.  (Added Feb. 5, 2021) [The Big Sleep: BigGANxCLIP.ipynb - Colaboratory](https://colab.research.google.com/drive/1NCceX2mbiKOSlAd_o7IU7nA9UskKN5WR?usp=sharing) by advadnoun. Uses BigGAN to generate images. To my knowledge, this is the first CLIP-steered BigGAN app that was released. [Instructions and examples](https://www.reddit.com/r/MachineLearning/comments/kzr4mg/p_the_big_sleep_texttoimage_generation_using/). [Notebook copy](https://colab.research.google.com/github/levindabhi/CLIP-Notebooks/blob/main/The_Big_Sleep_BigGANxCLIP.ipynb) by levindabhi. User advadnoun has additional Google Colab notebook(s) and other related material available at [his Patreon account](https://twitter.com/advadnoun/status/1366238021742333954), including a purportedly improved version of The Big Sleep.

3.  (Added Feb. 15, 2021) [Drive-Integrated The Big Sleep: BigGANxCLIP.ipynb - Colaboratory](https://colab.research.google.com/drive/1yFzzffr1wo_DAQ3pmjmN_hmN2ympM2E-?usp=sharing) by advadnoun. Uses BigGAN to generate images.

4.  (Added Feb. 5, 2021) [Big Sleep - Colaboratory](https://colab.research.google.com/drive/1MEWKbm-driRNF8PrU7ogS5o3se-ePyPb?usp=sharing) by lucidrains. Uses BigGAN to generate images. The GitHub repo has a local machine version. [GitHub](https://github.com/lucidrains/big-sleep). [How to use the latest features in Colab](https://www.reddit.com/r/bigsleep/comments/lxawb4/how_to_use_some_of_the_newer_features_of/).

5.  (Added Feb. 5, 2021) [The Big Sleep Customized NMKD Public.ipynb - Colaboratory](https://colab.research.google.com/drive/1Q2DIeMqYm_Sc5mlurnnurMMVqlgXpZNO?usp=sharing) by nmkd. Uses BigGAN to generate images. Allows multiple samples to be generated in a run.

6.  (Added Feb. 5, 2021) [Text2Image - Colaboratory](https://colab.research.google.com/github/tg-bomze/collection-of-notebooks/blob/master/Text2Image.ipynb) by tg_bomze. Uses BigGAN to generate images. [GitHub](https://github.com/tg-bomze/collection-of-notebooks).

7.  (Added Feb. 5, 2021) [Text2Image_v2 - Colaboratory](https://colab.research.google.com/github/tg-bomze/collection-of-notebooks/blob/master/Text2Image_v2.ipynb) by tg_bomze. Uses BigGAN to generate images. [GitHub](https://github.com/tg-bomze/collection-of-notebooks).

8.  (Added Feb. 5, 2021) [Text2Image_v3 - Colaboratory](https://colab.research.google.com/github/tg-bomze/collection-of-notebooks/blob/master/Text2Image_v3.ipynb) by tg_bomze. Uses BigGAN (default) or Sigmoid to generate images. [GitHub](https://github.com/tg-bomze/collection-of-notebooks).

9.  (Added Feb. 26, 2021) [Image Guided Big Sleep Public.ipynb - Colaboratory](https://colab.research.google.com/drive/1vOjrWwOh8E-EZXhOLpVm7Aw0m1i-fj8C?usp=sharing) by jdude_. Uses BigGAN to generate images. [Reddit post](https://www.reddit.com/r/deepdream/comments/lsylr1/image_guided_bigsleep_notebook/).

10.  (Added Feb. 5, 2021) [ClipBigGAN.ipynb - Colaboratory](https://colab.research.google.com/github/eyaler/clip_biggan/blob/main/ClipBigGAN.ipynb) by eyaler. Uses BigGAN to generate images/videos. [GitHub](https://github.com/eyaler/clip_biggan). [Notebook copy](https://colab.research.google.com/github/levindabhi/CLIP-Notebooks/blob/main/ClipBigGAN.ipynb) by levindabhi.

11.  (Added Feb. 5, 2021) [WanderCLIP.ipynb - Colaboratory](https://colab.research.google.com/github/eyaler/clip_biggan/blob/main/WanderCLIP.ipynb) by eyaler. Uses BigGAN (default) or Sigmoid to generate images/videos. [GitHub](https://github.com/eyaler/clip_biggan).

12.  (Added March 23, 2021) [Big Sleep - Colaboratory](https://colab.research.google.com/drive/1l7XSQX5lWnNJgxG8wSWFA_zoOfyNf6dc?usp=sharing) by LtqxWYEG. Uses BigGAN to generate images. [Reference](https://github.com/lucidrains/big-sleep/issues/51).

13.  (Added March 23, 2021) [Big Sleep Tweaked - Colaboratory](https://colab.research.google.com/drive/1uKedp1ArbWStSv0UlJJ6KUo2rW1t7TCT?usp=sharing) by scrunguscrungus. Uses BigGAN to generate images.

14.  (Added March 15, 2021) [Big-Sleep w/ EMA and Video Creation - Colaboratory](https://colab.research.google.com/gist/afiaka87/db1a3759aa23f5fcebeae93b32f35e9a/big-sleep-w-ema-and-video-creation.ipynb) by afiaka87\. Uses BigGAN to generate images. [Reddit post](https://www.reddit.com/r/bigsleep/comments/m61wph/new_item_added_to_my_list_colab_notebook_bigsleep/).

15.  (Added Feb. 5, 2021) [Story2Hallucination.ipynb - Colaboratory](https://colab.research.google.com/drive/1yNkvkrHApFR6alyFC1EzhPGHs86yjH1P?usp=sharing) by bonkerfield. Uses BigGAN to generate images/videos. [GitHub](https://github.com/lots-of-things/Story2Hallucination).

16.  (Added Feb. 7, 2021) [Story2Hallucination_GIF.ipynb - Colaboratory](https://colab.research.google.com/github/lots-of-things/Story2Hallucination/blob/main/Story2Hallucination_GIF.ipynb) by bonkerfield. Uses BigGAN to generate images. [GitHub](https://github.com/lots-of-things/Story2Hallucination).

17.  (Added April 7, 2021) [Journey in the Big Sleep: BigGANxCLIP.ipynb - Colaboratory](https://colab.research.google.com/drive/1WiGLsCgVG36clnZOAvPwADTfQB3FLq-o?usp=sharing) by brian_l_d. Uses BigGAN to generate images/videos. [Twitter reference](https://twitter.com/brian_l_d/status/1378550607863156736). [Example](https://www.reddit.com/r/bigsleep/comments/mmbscm/new_item_added_to_my_list_colab_notebook_journey/).

18.  (Added March 23, 2021) [Rerunning Latents - Colaboratory](https://colab.research.google.com/github/PHoepner/big-sleep/blob/main/Rerunning_Latents.ipynb) by PHoepner. Uses BigGAN to generate images. [Reference](https://www.reddit.com/r/bigsleep/comments/m9ctr5/technical_demo_catcharcoal_paintingpicassogorilla/).

19.  (Added March 23, 2021) [Looped Gif Creator - Colaboratory](https://colab.research.google.com/github/PHoepner/big-sleep/blob/main/Looped_Gif_Creator.ipynb) by PHoepner. Uses BigGAN to generate images. [Reference #1](https://www.reddit.com/r/bigsleep/comments/m8nixf/using_big_sleep_to_regenerate_animations/). [Reference #2](https://www.reddit.com/r/MediaSynthesis/comments/m8ztu1/using_modified_big_sleep_to_preserve_latent_path/).

20.  (Added March 23, 2021) [Morph - Colaboratory](https://colab.research.google.com/github/PHoepner/big-sleep/blob/main/Morph.ipynb) by PHoepner. This Colab notebook uses as input .pth files that are created by PHoepner's other Colab notebooks. [Reference](https://www.reddit.com/r/bigsleep/comments/m8nixf/using_big_sleep_to_regenerate_animations/grim2mj).

21.  (Added Feb. 24, 2021) [Colab-BigGANxCLIP.ipynb - Colaboratory](https://colab.research.google.com/github/styler00dollar/Colab-BigGANxCLIP/blob/main/Colab-BigGANxCLIP.ipynb) by styler00dollar. Uses BigGAN to generate images. "Just a more compressed/smaller version of that [advadnoun's] notebook". [GitHub](https://github.com/styler00dollar/Colab-BigGANxCLIP).

22.  (Added March 16, 2021) [AuViMi](https://github.com/NotNANtoN/AuViMi) by NotNANtoN. Uses BigGAN or SIREN to generate images.

23.  (Added Feb. 5, 2021) [CLIP-GLaSS.ipynb - Colaboratory](https://colab.research.google.com/drive/1fWka_U56NhCegbbrQPt4PWpHPtNRdU49?usp=sharing) by Galatolo. Uses BigGAN (default) or StyleGAN to generate images. The GPT2 config is for image-to-text, not text-to-image. [GitHub](https://github.com/galatolofederico/clip-glass).

24.  (Added Feb. 15, 2021) [dank.xyz](https://dank.xyz/). Uses BigGAN or StyleGAN to generate images. An easy-to-use website for accessing The Big Sleep and CLIP-GLaSS. To my knowledge this site is not affiliated with the developers of The Big Sleep or CLIP-GLaSS. [Reddit reference](https://www.reddit.com/r/MediaSynthesis/comments/l8xlr8/big_sleep_a_lightsaber_in_the_jungle/glh5nxl/).

25.  (Added Feb. 25, 2021) [Aleph-Image: CLIPxDAll-E.ipynb - Colaboratory](https://colab.research.google.com/drive/1Q-TbYvASMPRMXCOQjkxxf72CXYjR_8Vp?usp=sharing) by advadnoun. Uses DALL-E's discrete VAE (variational autoencoder) component to generate images. [Twitter reference](https://twitter.com/advadnoun/status/1364822183751471109). [Reddit post](https://www.reddit.com/r/MachineLearning/comments/ls0e0f/p_texttoimage_google_colab_notebook_alephimage/).

26.  (Added Feb. 26, 2021) [Aleph2Image (Delta): CLIP+DALL-E decoder.ipynb - Colaboratory](https://colab.research.google.com/drive/1oA1fZP7N1uPBxwbGIvOEXbTsq2ORa9vb?usp=sharing) by advadnoun. Uses DALL-E's discrete VAE (variational autoencoder) component to generate images. [Twitter reference](https://twitter.com/advadnoun/status/1365439793602064391). [Reddit post](https://www.reddit.com/r/deepdream/comments/ltcqdh/new_google_colab_notebook_texttoimage_for_text_a/).

27.  (Added Feb. 27, 2021) [Copy of working wow good of gamma aleph2img.ipynb - Colaboratory](https://colab.research.google.com/drive/1VAO22MNQekkrVq8ey2pCRznz4A0_jY29?usp=sharing) by advadnoun. Uses DALL-E's discrete VAE (variational autoencoder) component to generate images. [Twitter reference](https://twitter.com/advadnoun/status/1365786025277018115).

28.  (Added March 9, 2021) [improving of Aleph2Image (delta): CLIP+DALL-E decoder.ipynb - Colaboratory](https://colab.research.google.com/drive/1NGM9L8qP0gwl5z5GAuB_bd0wTNsxqclG?usp=sharing) by advadnoun. Uses DALL-E's discrete VAE (variational autoencoder) component to generate images. [Twitter reference](https://twitter.com/Ted_Underwood/status/1369260153426620417).

29.  (Added Feb. 27, 2021) [Aleph-Image: CLIPxDAll-E (with white blotch fix #2) - Colaboratory](https://colab.research.google.com/drive/1Fb7qTCumPvzSLp_2GMww4OV5BZdE-vKJ?usp=sharing) by thomash. Uses DALL-E's discrete VAE (variational autoencoder) component to generate images. Applies the white blotch fix mentioned [here](https://twitter.com/NJetchev/status/1365435397506007043) to advadnoun's "Aleph-Image: CLIPxDAll-E" notebook.

30.  (Added Feb. 28, 2021) [DALLECLIP](https://github.com/vipermu/DALLECLIP) by vipermu. Uses DALL-E's discrete VAE (variational autoencoder) component to generate images. [Twitter reference](https://twitter.com/viccpoes/status/1366060846716252160).

31.  (Added March 1, 2021) [Aphantasia.ipynb - Colaboratory](https://colab.research.google.com/github/eps696/aphantasia/blob/master/Aphantasia.ipynb) by eps696\. Uses FFT (Fast Fourier Transform) from Lucent/Lucid to generate images. [GitHub](https://github.com/eps696/aphantasia). [Twitter reference](https://twitter.com/eps696/status/1366568644084461570). [Example #1](https://www.reddit.com/r/deepdream/comments/lvu7u7/new_texttoimage_google_colab_notebook_aphantasia/). [Example #2](https://www.reddit.com/r/deepdream/comments/lvxqa7/texttoimage_for_text_gwen_stefani_at_the_great/).

32.  (Added March 4, 2021) [Illustra.ipynb - Colaboratory](https://colab.research.google.com/github/eps696/aphantasia/blob/master/Illustra.ipynb) by eps696\. Uses FFT (Fast Fourier Transform) from Lucent/Lucid to generate images. [GitHub](https://github.com/eps696/aphantasia).

33.  (Added Feb. 18, 2021) [Text2Image FFT.ipynb - Colaboratory](https://colab.research.google.com/drive/1rJMSyF_dmpL1kmse7Rm9TurjihJ_cA5t) by eps696\. Uses FFT (Fast Fourier Transform) from Lucent/Lucid to generate images. eps696 [suggests](https://twitter.com/eps696/status/1367845732703698947) to use his Aphantasia notebook instead of this one. [Twitter reference](https://twitter.com/eps696/status/1362262010763821056). [Example #1](https://www.reddit.com/r/deepdream/comments/lmoa8y/new_texttoimagevideo_notebook_text2image_fft_from/). [Example #2](https://www.reddit.com/r/deepdream/comments/lmpb3v/google_colab_notebook_text2image_fft_from_eps696/).

34.  (Added Feb. 14, 2021) [GA StyleGAN2 WikiArt CLIP Experiments - Pytorch - clean - Colaboratory](https://colab.research.google.com/drive/1ZSIVnriA5xf1umAegtbhtM0qzL3AT1rR?usp=sharing) by pbaylies. Uses StyleGAN to generate images. [More info](https://twitter.com/pbaylies/status/1360792281498943490).

35.  (Added Feb. 15, 2021) [StyleCLIP - Colaboratory](https://colab.research.google.com/github/orpatashnik/StyleCLIP/blob/main/playground.ipynb) by orpatashnik. Uses StyleGAN to generate images. [GitHub](https://github.com/orpatashnik/StyleCLIP). [Twitter reference](https://twitter.com/OPatashnik/status/1361220550027325443). [Reddit post](https://www.reddit.com/r/MediaSynthesis/comments/ll5ann/edit_a_human_face_image_with_texttoimage_using/).

36.  (Added Feb. 15, 2021) [StyleCLIP](https://github.com/vipermu/StyleCLIP) by vipermu. Uses StyleGAN to generate images.

37.  (Added Feb. 24, 2021) [CLIP_StyleGAN.ipynb - Colaboratory](https://colab.research.google.com/github/levindabhi/CLIP-Notebooks/blob/main/CLIP_StyleGAN.ipynb) by levindabhi. Uses StyleGAN to generate images.

38.  (Added Feb. 23, 2021) [TediGAN - Colaboratory](https://colab.research.google.com/github/weihaox/TediGAN/blob/main/playground.ipynb) by weihaox. Uses StyleGAN to generate images. [GitHub](https://github.com/weihaox/TediGAN). I got error "No pre-trained weights found for perceptual model!" when I used the Colab notebook, which was fixed when I made the change mentioned [here](https://github.com/weihaox/TediGAN/issues/3). After this change, I still got an error in the cell that displays the images, but the results were in the remote file system. Use the "Files" icon on the left to browse the remote file system.

39.  (Added March 7, 2021) [StyleGAN2-CLIP-approach.ipynb - Colaboratory](https://colab.research.google.com/drive/1IN3IgWQoB9WZGyz689COSGNnvnz7lIFI?usp=sharing) by l4rz. Uses StyleGAN to generate images. [GitHub](https://github.com/l4rz/stylegan2-clip-approach). [Twitter reference](https://twitter.com/l4rz/status/1367853921427984390).

40.  (Added March 13, 2021) [StyleGAN2_CLIP_approach_furry.ipynb - Colaboratory](https://colab.research.google.com/drive/1HZkziNj-W4E23JPewT5WcxMoI7rVk3MV) by saralexxia. Uses StyleGAN to generate images. [Reddit reference](https://www.reddit.com/r/MediaSynthesis/comments/m1ox7n/i_modified_stylegan2_clip_to_use_arfas_furry/).

41.  (Added March 7, 2021) [projector_clip.py](https://gist.github.com/pbaylies/671ef8434fd11f056bab4330e0e7c365) by pbaylies. Uses StyleGAN to generate images. [Twitter reference](https://twitter.com/pbaylies/status/1368371301639938049).

42.  (Added March 23, 2021) [ClipCarOptimizev2 - Colaboratory](https://colab.research.google.com/github/EvgenyKashin/random-colabs/blob/master/ClipSG2Optimize.ipynb) by EvgenyKashin. Uses StyleGAN to generate images. [GitHub](https://github.com/EvgenyKashin/random-colabs).

43.  (Added April 3, 2021) [stylegan ada w/ clip by chloe](https://colab.research.google.com/drive/1J8xyNRTNVnkNbQJnidcgSdDCHHKfGa8N?usp=sharing) by kingchloexx. Uses StyleGAN to generate images.

44.  (Added Feb. 5, 2021) [TADNE and CLIP - Colaboratory](https://colab.research.google.com/github/nagolinc/notebooks/blob/main/TADNE_and_CLIP.ipynb) by nagolinc. Uses TADNE ("This Anime Does Not Exist") to generate images. [GitHub](https://github.com/nagolinc/notebooks).

45.  (Added Feb. 5, 2021) [CLIP + TADNE (pytorch) v2 - Colaboratory](https://colab.research.google.com/github/nagolinc/notebooks/blob/main/CLIP_%2B_TADNE_(pytorch)_v2.ipynb) by nagolinc. Uses TADNE ("This Anime Does Not Exist") to generate images. [Instructions and examples](https://www.reddit.com/r/MediaSynthesis/comments/l9lbfy/instructions_for_using_free_animecentric_google/). [GitHub](https://github.com/nagolinc/notebooks). [Notebook copy](https://colab.research.google.com/github/nagolinc/notebooks/blob/main/CLIP_%2B_TADNE_(pytorch)_v2.ipynb) by levindabhi

46.  (Added March 18, 2021) [TADNE Projection +guided sampling via CLIP - Colaboratory](https://colab.research.google.com/drive/1p03gWLGgQU7IAY44O1_vWnIPN_D0o9_v?usp=sharing) by halcy. Uses TADNE ("This Anime Does Not Exist") to generate images. I needed 2 changes to get this to work: 1) Change line "gdown.download('<https://drive.google.com/uc?id=1qNhyusI0hwBLI-HOavkNP5I0J0-kcN4C>', 'network-tadne.pkl', quiet=False)" to "gdown.download('<https://drive.google.com/uc?id=1LCkyOPmcWBsPlQX_DxKAuPM1Ew_nh83I>', 'network-tadne.pkl', quiet=False)" 2) Change line "_G, _D, Gs = pickle.load(open("/content/network-tadne.pkl", "rb"))" to "_G, _D, Gs = pickle.load(open("/content/stylegan2/network-tadne.pkl", "rb"))". [Twitter reference](https://twitter.com/halcy/status/1353870382869131265).

47.  (Added Feb. 24, 2021) [clipping-CLIP-to-GAN](https://github.com/cloneofsimo/clipping-CLIP-to-GAN) by cloneofsimo. Uses FastGAN to generate images.

48.  (Added Feb. 5, 2021) [CLIP & gradient ascent for text-to-image (Deep Daze?).ipynb - Colaboratory](https://colab.research.google.com/drive/1FoHdqoqKntliaQKnMoNs3yn5EALqWtvP?usp=sharing) by advadnoun. Uses SIREN to generate images. To my knowledge, this is the first app released that uses CLIP for steering image creation. [Instructions and examples](https://www.reddit.com/r/MachineLearning/comments/ky8fq8/p_a_colab_notebook_from_ryan_murdock_that_creates/). [Notebook copy](https://colab.research.google.com/github/levindabhi/CLIP-Notebooks/blob/main/CLIP_%26_gradient_ascent_for_text_to_image_(Deep_Daze%20).ipynb) by levindabhi.

49.  (Added Feb. 5, 2021) [Deep Daze - Colaboratory](https://colab.research.google.com/drive/1_YOHdORb0Fg1Q7vWZ_KlrtFe9Ur3pmVj?usp=sharing) by lucidrains. Uses SIREN to generate images. The GitHub repo has a local machine version. [GitHub](https://github.com/lucidrains/deep-daze). [Notebook copy](https://colab.research.google.com/github/levindabhi/CLIP-Notebooks/blob/main/Deep_Daze.ipynb) by levindabhi.

50.  (Added Feb. 5, 2021) [CLIP-SIREN-WithSampleDL.ipynb - Colaboratory](https://colab.research.google.com/drive/1K1vfpTEvAmxW2rnhAaALRVyis8EiLOnD?usp=sharing) by norod78\. Uses SIREN to generate images.

51.  (Added Feb. 17, 2021) [Text2Image Siren+.ipynb - Colaboratory](https://colab.research.google.com/drive/1L14q4To5rMK8q2E6whOibQBnPnVbRJ_7) by eps696\. Uses SIREN to generate images. [Twitter reference](https://twitter.com/eps696/status/1360973092722528256). [Example #1](https://www.reddit.com/r/deepdream/comments/lm9evo/colab_notebook_text2image_siren_seems_to_be/). [Example #2](https://www.reddit.com/r/deepdream/comments/lm3cg3/texttoimage_editing_of_an_existing_image_with/). [Example #3](https://www.reddit.com/r/deepdream/comments/lm3t7z/texttoimage_generation_for_text_a_firebreathing/).

52.  (Added March 15, 2021) [deep-daze Fourier Feature Map - Colaboratory](https://colab.research.google.com/gist/afiaka87/e018dfa86d8a716662d30c543ce1b78e/text2image-siren.ipynb) by afiaka87\. Uses SIREN to generate images. [Reference](https://github.com/lucidrains/deep-daze/issues/59). [Reddit post](https://www.reddit.com/r/bigsleep/comments/m61ean/new_item_added_to_my_list_colab_notebook_deepdaze/).

53.  (Added March 8, 2021) [Aleph2Image Modified by kingchloexx for Image+Text to Image - Colaboratory](https://colab.research.google.com/drive/1kHZJ0spQexyz67XTVszGncCLATWx1y42?usp=sharing) by kingchloexx. Uses SIREN to generate images. [Example](https://www.reddit.com/r/deepdream/comments/m101tr/new_google_colab_notebook_aleph2image_modified_by/).

54.  (Added Feb. 24, 2021) [Colab-deep-daze - Colaboratory](https://colab.research.google.com/github/styler00dollar/Colab-deep-daze/blob/main/Colab-Deep-Daze.ipynb) by styler00dollar. Uses SIREN to generate images. I did not get this notebook to work, but your results may vary. [GitHub](https://github.com/styler00dollar/Colab-deep-daze).

55.  (Added March 8, 2021) [CLIP Style Transfer Test.ipynb - Colaboratory](https://colab.research.google.com/drive/11nQXygNzuEMG_-CU0jHLLNGzlq6SRpKx?usp=sharing) by Zasder3\. Uses VGG19's conv4_1 to generate images. [GitHub](https://github.com/Zasder3/CLIP-Style-Transfer). [Twitter reference](https://twitter.com/CadeGordonML/status/1368988421126033408).

56.  (Added March 9, 2021) [PaintCLIP.ipynb - Colaboratory](https://colab.research.google.com/drive/1Sg3o3hN2S2TqYKxF-X8WPmdWPzDszTBK?usp=sharing) by advadnoun. Uses [Stylized Neural Painter](https://jiupinjia.github.io/neuralpainter/) to generate images. As of time of writing, this gave me an error message.

57.  (Added March 9, 2021) [VectorAscent](https://github.com/ajayjain/VectorAscent) by ajayjain. Uses diffvg to generate images.

58.  (Added March 23, 2021) [ClipMeshOptimize.ipynb - Colaboratory](https://colab.research.google.com/github/EvgenyKashin/random-colabs/blob/master/ClipMeshOptimize.ipynb) by EvgenyKashin. Uses PyTorch3D to generate images. [GitHub](https://github.com/EvgenyKashin/random-colabs).

List of sites/programs/projects that let you use CLIP to rate how well image(s) match text description(s):

1.  (Added Feb. 5, 2021) [Zero shot image classifier](https://clip.backprop.co/) by Backprop. The percentages for the CLIP labels are relative to one another and always sum to 100%.

2.  (Added Feb. 21, 2021) [CLIP Playground](https://www.clipplayground.co/).

3.  (Added March 8, 2021) [Saliency Map demo for CLIP](https://ganpaint.io/miniclip/). [GitHub](https://github.com/HendrikStrobelt/miniClip).

List of related lists:

1.  (Added Aug. 11, 2021) [Text-to-Image Summary](https://softologyblog.wordpress.com/2021/06/10/text-to-image-summary/).

2.  (Added Aug. 23, 2021) [List of VQGAN+CLIP Implementations](https://ljvmiranda921.github.io/notebook/2021/08/11/vqgan-list/).

3.  (Added Feb. 24, 2021) [Text-to-image Colab notebooks](http://colabnotebooks.com/submit_cat/text-to-image/).

4.  (Added March 2, 2021) [GitHub projects with tag "text-to-image"](https://github.com/topics/text-to-image).

List of subreddits in which you can view or post images/videos from the sites/programs/projects listed in this post:

1.  [r/bigsleep](https://www.reddit.com/r/bigsleep/) (subreddit for images/videos generated from text-to-image machine learning algorithms).

2.  [r/deepdream](https://www.reddit.com/r/deepdream/) (subreddit for images/videos generated from machine learning algorithms).

3.  [r/mediasynthesis](https://www.reddit.com/r/mediasynthesis/) (subreddit for media generation/manipulation techniques that use artificial intelligence; this subreddit shouldn't be used to post images/videos unless new techniques are demonstrated, or the images/videos are of high quality relative to other posts).

List of image upscalers and/or denoisers:

1.  (Added March 3, 2021) [Bigjpg](https://bigjpg.com/). Image upscaling with optional denoising.

2.  (Added March 23, 2021) [waifu2x](http://waifu2x.udp.jp/). Image upscaling and/or denoising.

3.  (Added March 3, 2021) [ESRGAN.ipynb - Colaboratory](https://colab.research.google.com/github/dvschultz/ESRGAN/blob/master/ESRGAN.ipynb). Image upscaling by 4 times the original resolution using ERSGAN.

List of lists of image-related machine learning apps:

1.  (Added March 23, 2021) [A list of Machine Learning Art Colabs](https://github.com/dvschultz/ml-art-colabs).

2.  (Added Feb. 5, 2021) [Generative Tools](https://docs.google.com/document/d/1N57oAF7j9SuHcy5zg2VZWhttLwR_uEldeMr-VKzlVIQ) by eyaler. [Shortened link](https://j.mp/generativetools).

3.  (Added Aug. 12, 2021) [styler00dollar's list of audiovisual Google Colabs](https://github.com/styler00dollar/dl-colab-notebooks).
